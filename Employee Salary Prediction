import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, mean_squared_error, r2_score

# --- 1. Load and Clean the Data ---
# Load the dataset and directly replace '?' values and drop the 'education' column.
data = pd.read_csv("/content/adult 3.csv")
data['workclass'] = data['workclass'].replace({'?': 'Others'})
data['occupation'] = data['occupation'].replace({'?': 'Others'})
data = data.drop(columns=['education'])

# --- 2. Encode Categorical Features ---
# Convert each text column to numbers individually.
le = LabelEncoder()
data['workclass'] = le.fit_transform(data['workclass'])
data['marital-status'] = le.fit_transform(data['marital-status'])
data['occupation'] = le.fit_transform(data['occupation'])
data['relationship'] = le.fit_transform(data['relationship'])
data['race'] = le.fit_transform(data['race'])
data['gender'] = le.fit_transform(data['gender'])
data['native-country'] = le.fit_transform(data['native-country'])
data['income'] = le.fit_transform(data['income'])

# --- 3. Split and Scale the Data ---
# Define features (X) and target (y), then split into training and testing sets.
X = data.drop(columns=['income'])
y = data['income']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features.
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# --- 4. Logistic Regression: Train, Evaluate, and Plot ---
print("\n--- Training Logistic Regression ---")
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

# Make predictions and get the accuracy.
lr_predictions = lr_model.predict(X_test)
lr_accuracy = accuracy_score(y_test, lr_predictions)
print(f"Accuracy: {lr_accuracy:.4f}")
print(classification_report(y_test, lr_predictions))

# Generate and display the Confusion Matrix.
lr_cm = confusion_matrix(y_test, lr_predictions)
plt.figure(figsize=(6, 5))
sns.heatmap(lr_cm, annot=True, fmt="d", cmap="Blues")
plt.title("Logistic Regression - Confusion Matrix")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

# Generate and display the ROC Curve.
lr_probas = lr_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, lr_probas)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}", color="darkorange")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.title("Logistic Regression - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid(True)
plt.show()


# --- 5. Random Forest: Train, Evaluate, and Plot ---
print("\n--- Training Random Forest ---")
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

# Make predictions and get the accuracy.
rf_predictions = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_predictions)
print(f"Accuracy: {rf_accuracy:.4f}")
print(classification_report(y_test, rf_predictions))

# Generate and display the Confusion Matrix.
rf_cm = confusion_matrix(y_test, rf_predictions)
plt.figure(figsize=(6, 5))
sns.heatmap(rf_cm, annot=True, fmt="d", cmap="Greens")
plt.title("Random Forest - Confusion Matrix")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

# Generate and display the ROC Curve.
rf_probas = rf_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, rf_probas)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}", color="darkgreen")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.title("Random Forest - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid(True)
plt.show()

# --- 6. Linear Regression: Train and Evaluate ---
print("\n--- Training Linear Regression ---")
# Linear Regression is typically used for regression tasks, not classification.
# However, we can use it to predict a continuous value and then threshold it for classification.
# This is generally not recommended for classification problems, but included as requested.
lr_reg_model = LinearRegression()
lr_reg_model.fit(X_train, y_train)

# Make predictions and evaluate.
lr_reg_predictions = lr_reg_model.predict(X_test)
# Threshold predictions at 0.5 for binary classification
lr_reg_predictions_classified = (lr_reg_predictions > 0.5).astype(int)

# Evaluate using classification metrics
lr_reg_accuracy = accuracy_score(y_test, lr_reg_predictions_classified)
print(f"Accuracy (thresholded): {lr_reg_accuracy:.4f}")
print(classification_report(y_test, lr_reg_predictions_classified))

# --- 7. K-Nearest Neighbors: Train, Evaluate, and Plot ---
print("\n--- Training K-Nearest Neighbors ---")
knn_model = KNeighborsClassifier()
knn_model.fit(X_train, y_train)

# Make predictions and get the accuracy.
knn_predictions = knn_model.predict(X_test)
knn_accuracy = accuracy_score(y_test, knn_predictions)
print(f"Accuracy: {knn_accuracy:.4f}")
print(classification_report(y_test, knn_predictions))

# Generate and display the Confusion Matrix.
knn_cm = confusion_matrix(y_test, knn_predictions)
plt.figure(figsize=(6, 5))
sns.heatmap(knn_cm, annot=True, fmt="d", cmap="Purples")
plt.title("KNN - Confusion Matrix")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

# Generate and display the ROC Curve.
knn_probas = knn_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, knn_probas)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}", color="darkviolet")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.title("KNN - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid(True)
plt.show()


# --- 8. Compare Model Accuracies ---
# Create a bar chart comparing the accuracy of all models.
model_names = ["Logistic Regression", "Random Forest", "Linear Regression (Thresholded)", "KNN"]
accuracies = [lr_accuracy, rf_accuracy, lr_reg_accuracy, knn_accuracy]

plt.figure(figsize=(10, 6))
plt.bar(model_names, accuracies, color=['skyblue', 'lightgreen', 'salmon', 'plum'])
plt.ylabel("Accuracy Score")
plt.title("Model Accuracy Comparison")
plt.ylim(0.8, 0.9) # Adjust ylim as needed based on results
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 0.002, f'{acc:.4f}', ha='center', fontsize=12)
plt.show()
